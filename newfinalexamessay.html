<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Umtha-Unathi's Website</title>
    <!-- Box-icon -->
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
    <link rel="stylesheet" href="essay.css">
</head>
<body>
    <header>
        <div class="nav container">
            <a href="index.html" class="logo">Umtha-Unathi<span>blogposts</span></a>
            <a href="index.html" class="login">HOME</a>
            <a href="#PostInformation" class="login">POST</a>
            <a href="#" class="login">PAGE UP</a>
        </div>
    </header>

    <section class="home" id="home">
        <div class="home-text container">
            <h2 class="home-title">Umtha-Unathi's Essay</h2>
            <span class="home-subtitle">Feel free to take a peek</span>
        </div>
    </section>

    <section class="about container" id="#PostInformation">
        <div class="contentBx">
            <h2 class="titleText">Umtha-Unathi</h2>
            <p class="title-text">
<p>Here is Umtha-Unathi's Essay:</p>

WSOA3028A_FinalEssay_2483967 

 

The Center for AI safety (CAIS) and numerous notable public figures, AI scientists and world leaders representing issued a document in May 2023 known as the Statement on Al Risk. With over 350+ signatories being represented by the CAIS, it functions as a critical statement on the risks of AI. This is a vital document demonstrating the escalating consciousness and apprehensions regarding the moral and social implications of Al in and amongst AI experts and society alike. It shows that CAIS, along with all the signatories, is addressing growing concerns around algorithmic culture and AI whilst promoting a more prudent and accountable application of Al in the world. As a result, there is an insurance of transparency, accountability, and ethical concepts during Al development and its use. The statement aims to increase awareness and offer direction to institutions, companies, research facilities, and academic services resulting from the increased insurgence of the application of Artificial Intelligence (Al) in the world. The document highlights how the importance of responsibly mitigating the risk of extinction from AI is of utmost importance ranking with societal-scale risks such as pandemics and nuclear war. 

  

Furthermore, signatories aim to publicly demonstrate the growing concern amongst AI experts and public figures around the severity of risk pertaining to the continued development of AI (CAIS, 2023). Algorithms, once obscure, are now being subjected to considerable popular and scholarly scrutiny. 

  

Algorithms, once obscure, are now being subjected to considerable popular and scholarly scrutiny (Dourish, 2016). Algorithmic bias presents a major ethical challenge in the realm of algorithmic culture because algorithms have been integrated into our day to day lives and thus become part of the conversation about how our lives are organized (Dourish, 2016). With reference, to how certain groups of people are systemically discriminated against and treated unfairly due to biased data or algorithms that reinforce existing patterns of inequality and discrimination in society. The likelihood of facial recognition algorithms incorrectly identifying people is higher for those with a darker complexion, as shown in numerous studies. Unjust treatment and surveillance by law enforcement agencies is a potential outcome of this formulating the way people of darker complexion are viewed and how they live their lives weary of being misidentified and charged with crimes and offenses they did not commit. Algorithmic culture's connection to privacy and data protection is a growing area of concern. The ethical implications surrounding the use and ownership of personal data are raised as data mining, profiling, and machine learning algorithms become increasingly prevalent. Privacy breaches, discrimination, and the violation of individual rights are potential consequences of using predictive algorithms in decision-making processes like credit scoring, hiring, and criminal justice. To guarantee ethical and transparent use, the design of these algorithms must be carefully executed. 

  

Algorithms have become objects of academic attention, often in the context of social and cultural concerns (Doursh, 2016). As the risk of using Al is defined in terms of unintended consequences like biases, errors, or harm to individuals or society (CAIS, 2023). Biases and individual harm to mental health and overall well-being can occur as outlined in the Wall Street Journal’s analysis of Artificial Intelligence in classrooms (Wall Street Journal, 2019). In this case study, Chinese schools have implemented AI in the form of Brain Wave trackers which measure a student’s engagement in the classroom and cumulate an attention score. This figure is accessed by the teachers and sent directly to parents. Whilst this results in boosted teacher-student engagement it offers a platform for bias and educational harm in the form of unwanted/unnecessary academic pressure. Students who are receiving low attention scores may be reprimanded by parents and pressured to increase their scores as well as the fact that academic scores are made public to all parents of students in the class resulting in students feeling embarrassed at their lower scores compared to others (Wall Street Journal, 2019). Furthermore, parents and teachers alike are unfamiliar (even unfazed) with the use and storage of students’ data, raising the ethical implications surrounding the use and ownership of their personal data. As data mining, profiling, and machine learning algorithms become increasingly prevalent in schools. Privacy breaches, discrimination, and the violation of individual student rights are becoming more evident. This case study shows that the consequences of using predictive algorithms in academic structures are not only the enhancement of student learning experience and better educational outcomes, but it also poses significant ethical challenges surrounding student wellbeing (bullying, social exclusion, and emotional harm) that should not be ignored (Wall Street Journal, 2019). 

  

The impact of algorithmic culture in AI and the internet can be analyzed through the lenses of three theoretical frameworks: the Internet, society, and design justice. Each framework offers unique insights into the consequences of algorithmic culture. 

  

  

Each framework will be analyzed in relation to mitigating the complex interplay between AI technology and human experience that can result in extinction as outlined by the CAIS and is scalable to extinction-level events such as pandemics and nuclear war (CAIS, 2023). The internet, as a transformative force, has shaped the way we communicate, access information, and interact with one another. It has facilitated the democratization of knowledge, empowered marginalized communities, and provided a platform for social and political engagement. However, the integration of algorithmic systems within the internet landscape has introduced a new dynamic. It can be said that the algorithms, driven by AI, now control what content we engage with, thus shaping our online experiences by harnessing algorithms made to analyze, understand, and predict our desired user experience on its platforms (Doroush, 2016). This raises concerns about the potential for entrenchment of existing biases. The internet, once celebrated for its ability to connect diverse voices, risks becoming a tool used for the reinforcement of pre-existing beliefs and limiting exposure to different perspectives. These challenges the ideal of an open and inclusive digital public platform. AI algorithms often create an illusion of autonomy, where they make decisions independently. However, these 

 

 algorithms are programmed by human designers, embodying biases, assumptions, and values that can perpetuate existing power imbalances. By relinquishing control to algorithms, we surrender our agency, allowing the technology to shape our experiences and decisions. This occurs because of algorithms positioning human beings as resources to be deployed to the internet according to pre-programmed responses (es (Doroush, 2016). Undermining our value as individuals and as a society by limiting our capacity to engage in critical thinking, creativity, and independent decision-making to the web browser or comment under a post on social media. 

  

Society plays a crucial role in shaping and being shaped by technology. The public's reaction to the integration of AI and algorithmic systems into society has both positive and negative implications. On one hand, the endorsement of AI as a system with the potential to improve efficiency, optimize resource allocation, and enhance decision-making processes results in increased user activity. However, with the effects of algorithmic culture not being voiced pertaining to its pervasive nature, there is a risk of human agency being undermined. The automation and optimization of various societal processes may lead to a loss of control, accountability, and transparency. Moreover, the reliance on AI may perpetuate inequalities, as algorithmic biases can disproportionately impact marginalized communities, Dourish outlines this in stating “statistical machine learning algorithms have no power to reveal what the algorithm knows, because the algorithm knows only about inexpressible commonalities in millions of pieces of training data” (Dourish, 2016) in other words the algorithm groups sets of similar data and we humans don’t actually knowing what the data is or necessarily how it is or isn’t being presented so without human interface the algorithm can present biased information. This is particularly crucial in the integration of AI in sectors such as employment, healthcare, and criminal justice as the complex ecosystem of the algorithm is based on the technological and social forces that shape it. The emergence of algorithmic culture and Al has led to new opportunities for interactive communication, information sharing, and collaborative problem-solving. This further puts into question the moral aspects related to the right to privacy, safety, and openness. As the CAIS statement details, significant risks such as the mismanagement of our society are presented from the lack of confidentiality and the algorithmic decision-making processes which have large scale ramifications, affecting individuals in society.  

  

The statement made by Harris states that, when we hand over the management of civilization to machines, we risk losing the incentive to actively participate in society and its governance (Ted-Ed, 2022). As AI assumes more responsibilities, humans may become complacent and detached from societal affairs, diminishing our sense of civic engagement and personal responsibility, and resulting in the destruction of political structures as we know them. This is a function of human nature we create machines and structures that will allow us to live with minimal effort. The increasing reliance on AI can lead to a society where humans are disempowered and infantilized, relegating critical decision-making and problem-solving to algorithms rather than cultivating these skills within us and future generations (Ted-Ed, 2022). AI-driven systems that prioritize efficiency, personalization, and convenience, undermine human connection, and lived experience. The creation of a society in which life is lived according to ones and zeros where we are reliant on the process of algorithmic curation of online content and social media feeds thus creating echo chambers that function to isolate individuals from diverse perspectives. This isolation hampers our ability and willingness to engage in meaningful dialogue, understand different viewpoints, and collectively address societal challenges, altering our motivations to do anything. I presume that without the integration of AI, we are offered a greater potential for fostering genuine human connections and enriching our lived experience, which is vital for a healthy and inclusive society. 

  

  

Design justice provides a critical framework for evaluating the impact of algorithmic culture in AI and the internet from a civil justice perspective. Design justice emphasizes the importance of inclusive, participatory, and equitable design processes that account for diverse communities’ needs, experiences, and values. In the context of algorithmic systems Doursh opts for increased human involvement with algorithms and the data they process diverse communities' needs, experiences, and values diverse communities' needs, experiences, and values for humans to narrate the datasets presented as signaling certain categories of people so that data can be used to inform us about the needs of particular groups of people and the representation of those groups (Doursh, 2016). Design justice raises concerns about the lack of diversity and representation in the development and deployment of AI technologies. The biases embedded in algorithms can perpetuate existing social inequalities and discrimination. The concentration of power and decision-making is placed in the hands of tech giants and powerful corporations thus raising questions about the principles of democratic governance and the potential for corporate interests to corrupt algorithmic culture and AI. Doursh calls for design justice and the involvement of marginalized communities by proposing the move from individual data to large data sets and from one person to a large population thus allowing for interdisciplinary collaboration, and transparency in algorithmic decision-making processes to mitigate the negative consequences of algorithmic culture (Doursh, 2016). Algorithmic culture risks perpetuating and amplifying existing inequalities, as algorithms reflect the biases present in the data they are trained on. This can lead to discriminatory outcomes in areas such as hiring, lending, and criminal justice. By allowing AI to govern societal processes, we risk entrenching and legitimizing these biases, hindering progress towards a more equitable society. Instead, focusing on design justice principles that emphasize human involvement will result in fairness, accountability, and inclusivity that will help address these challenges more effectively. 

  

In my review of the case studies presented above, I view the biggest pitfall of algorithmic culture as being the very thing that sparked it, human innovation, and industrialization. Humans have an innate desire to improve, atomize and develop. The case study, “Can we build AI without losing control over it?” by Sam Harris, emphasizes that “information explosion” (the process by which AI will become more intelligent than humans and thus start self-automating as a result of not having anything further to learn from humans) is not the most dangerous outcome, as predicted by many, of the integration of AI-based algorithmic culture in the theoretical frameworks however, that the divergence between AI goals and human goals will be the destruction of human civilization. And that the rate that algorithmic culture is developing is unprecedented and unpredictable. This is because Algorithmic culture AI is dependent on these three factors; Intelligence being the product of information processing (information is processed and knowledge is gained), the continued improvement of intelligent machines, and the notion that we do not know what the summit of intelligence is for Artificial Intelligence systems. The concept of continuous improvement of intelligent machines is dependent on the concept that we do not know the limit of artificial intelligence just the thought of creating something that may be smarter than us but having been built by us, humans, is a concept that human has been infatuated with since the start of us. The existence of “godlike” intelligence, something that is “all-knowing”, and humans are inferior to that we can physically see and communicate with. Begs the question of whether humans are creating such technology to rule over it and harness it or to have a physically manifested deity to be in awe of. 

  

The importance of the Internet, Society, and Design Justice theoretical frameworks has been emphasized by evaluating the impact of algorithmic culture and Al on the Internet. Algorithmic decision-making processes in various fields have had detrimental impacts on marginalized communities and human rights. Promoting transparency and upholding ethical standards are crucial while designing and deploying algorithmic culture and Al. The wider social implications should not be overlooked. By adopting more effective governance mechanisms, we can ensure that algorithmic culture and AI on the internet are used in ways that respect and uphold human dignity, respect, and freedom. Dire outcomes may result if not handled properly. 

 

Reference List: 

Doursh, P.(2016). Algorithms and their others: Algorithmic culture in context. 

ABC NEWS. (2023, June 26). Unraveling the Complexities: A Critical Analysis of the Decolonization of the Internet, Discriminatory Practices, and Governmental Use of AI [Video]. YouTube. Retrieved from https://www.youtube.com/watch?v=540vzMlf-54 

TED. (2023, June 26). Can we build AI without losing control over it? | Sam Harris [Video]. YouTube. Retrieved from https://www.youtube.com/watch?v=8nt3edWLgIg 

TED- Ed. (203, June 26). How will AI change the world? [Video]. YouTube. Retrieved from https://www.youtube.com/watch?v=RzkD_rTEBYs 

SafeAI. (2023, May). Statement on AI Risk. Retrieved from https://www.safe.ai/statement-on-ai-riskLinks 

 

 

 
            
        </div>
        <div class="imgBx">
            <img src="images/about.png" alt="" class="fitBg">
        </div>
    </section>

    <footer>
        <div class="footer-container">
            <div class="sec aboutus">
                <h2>About Him</h2>
                <p>Umtha-Unathi is a highly skilled game designer with a passion for innovation and creativity. His sharp mind, attention to detail, and relentless pursuit of perfection have earned him a reputation as one of the best in the industry. Born and raised in East London, at a young age and quickly became fascinated by the world of video games.</p>
                <ul class="sci">
                    <li><a href="#"><i class="bx bxl-facebook"></i></a></li>
                    <li><a href="#"><i class="bx bxl-instagram"></i></a></li>
                    <li><a href="#"><i class="bx bxl-twitter"></i></a></li>
                    <li><a href="#"><i class="bx bxl-linkedin"></i></a></li>
                </ul>
            </div>
            <div class="sec quicklinks">
                <h2>Quick Access</h2>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="profileandportfolio.html">About</a></li>
                </ul>
            </div>
            <div class="sec contactBx">
                <h2>Contact Info</h2>
                <ul class="info">
                    <li>
                        <span><i class='bx bxs-map'></i></span>
                        <span> Wits University <br> 1 Jan Smuts Ave, Braamfontein, Johannesburg, 2000 <br> RSA</span>
                    </li>
                    <li>
                        <span><i class='bx bx-envelope' ></i></span>
                        <p><a href="umthaoupa@gmail.com">umthaoupa@gmail.com</a></p>
                    </li>
                </ul>
            </div>
        </div>
    </footer>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js" integrity="sha512-aVKKRRi/Q/YV+4mjoKBsE4x3H+BkegoM/em46NNlCqNTmUYADjBbeNefNxYV7giUp0VxICtqdrbqU7iVaeZNXA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
    <script src="initial.js"></script>
</body>
</html>